spark-shell
val file = sc.textFile("s3://CommonCrawl/ibm/26279.gz")
val counts = file.flatMap(line => line.toLowerCase().replace(".", " ").replace(",", " ").split(" ")).map(word => (word, 1L)).reduceByKey(_ + _)
val sorted_counts = counts.collect().sortBy(wc => -wc._2)    (20mins)
sc.parallelize(sorted_counts.take(60000)).saveAsTextFile("s3://CommonCrawl/top60000_ibm.com")
sc.parallelize(sorted_counts).saveAsTextFile("s3://CommonCrawl/wordcount-ibm.com")
